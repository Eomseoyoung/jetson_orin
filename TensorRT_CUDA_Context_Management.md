# TensorRT ë‹¤ì¤‘ ëª¨ë¸ ì‚¬ìš© ì‹œ CUDA ì»¨í…ìŠ¤íŠ¸ ì¶©ëŒ í•´ê²° ë°©ë²•

## ë¬¸ì œ ìƒí™©

### ë°œìƒí•œ ì˜¤ë¥˜ë“¤
```bash
[TRT] [E] IExecutionContext::executeV2: Error Code 1: Cask (Cask convolution execution)
[TRT] [E] IExecutionContext::executeV2: Error Code 1: Cask (invalid resource handle)
[TRT] [E] IExecutionContext::executeV2: Error Code 1: Cask (CuTensor permutate execute failed)
```

### ë¬¸ì œ ì›ì¸ ë¶„ì„
- **TRTSegmenter**: `pycuda`ë¥¼ ì‚¬ìš©í•œ ëª…ì‹œì  CUDA ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
- **Ultralytics YOLO**: ë‚´ë¶€ì ìœ¼ë¡œ ìì²´ CUDA ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
- **ì¶©ëŒ ì§€ì **: ë‘ ì‹œìŠ¤í…œì´ ì„œë¡œ ë‹¤ë¥¸ CUDA ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ì†ŒìŠ¤ í•¸ë“¤ ì¶©ëŒ ë°œìƒ

### ë‹¨ì¼ ëª¨ë¸ vs ë‹¤ì¤‘ ëª¨ë¸
- **ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©** (`yolomodel_tensor_imagesize_test_sh.py`): ì •ìƒ ì‘ë™
- **ë‹¤ì¤‘ ëª¨ë¸ ì‚¬ìš©** (`main_tensor_sh.py`, `main_tensor.py` ë“±): TensorRT ì˜¤ë¥˜ ë°œìƒ

## í•´ê²° ë°©ë²•

### 1. CUDA ì»¨í…ìŠ¤íŠ¸ ëª…ì‹œì  ê´€ë¦¬

#### ê¸°ì¡´ ì½”ë“œ
```python
import pycuda.autoinit  # ìë™ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
```

#### ìˆ˜ì •ëœ ì½”ë“œ
```python
import pycuda.driver as cuda
# CUDA ì»¨í…ìŠ¤íŠ¸ ëª…ì‹œì  ê´€ë¦¬
cuda.init()
cuda_device = cuda.Device(0)
cuda_context = cuda_device.make_context()
```

### 2. TRTSegmenter.infer() ë©”ì†Œë“œ ë³´í˜¸

#### ê¸°ì¡´ ì½”ë“œ
```python
def infer(self, frame_bgr: np.ndarray) -> np.ndarray:
    x = self._preprocess(frame_bgr, self.in_h, self.in_w, self.mean_std_norm)
    np.copyto(self.h_inputs[self.in_name], x.ravel())
    cuda.memcpy_htod_async(self.d_inputs[self.in_name], self.h_inputs[self.in_name], self.stream)
    self.context.execute_async_v3(self.stream.handle)
    cuda.memcpy_dtoh_async(self.h_outputs[self.out_name], self.d_outputs[self.out_name], self.stream)
    self.stream.synchronize()
    y = np.array(self.h_outputs[self.out_name], copy=False).reshape(self.out_shape)
    return self._argmax_logits(y)
```

#### ìˆ˜ì •ëœ ì½”ë“œ
```python
def infer(self, frame_bgr: np.ndarray) -> np.ndarray:
    # CUDA ì»¨í…ìŠ¤íŠ¸ ëª…ì‹œì  ê´€ë¦¬
    cuda_context.push()
    try:
        x = self._preprocess(frame_bgr, self.in_h, self.in_w, self.mean_std_norm)
        np.copyto(self.h_inputs[self.in_name], x.ravel())
        cuda.memcpy_htod_async(self.d_inputs[self.in_name], self.h_inputs[self.in_name], self.stream)
        self.context.execute_async_v3(self.stream.handle)
        cuda.memcpy_dtoh_async(self.h_outputs[self.out_name], self.d_outputs[self.out_name], self.stream)
        self.stream.synchronize()
        y = np.array(self.h_outputs[self.out_name], copy=False).reshape(self.out_shape)
        return self._argmax_logits(y)
    finally:
        cuda_context.pop()
```

### 3. YOLO ëª¨ë¸ ì§€ì—° ë¡œë”© êµ¬í˜„

#### ê¸°ì¡´ ì½”ë“œ
```python
# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ì¦‰ì‹œ ë¡œë”©
signal_model = YOLO("model/all_signal_augmentation.engine")
yolo_models = YOLO("model/1024x512.engine")
split_model = YOLO("model/sp.engine")
```

#### ìˆ˜ì •ëœ ì½”ë“œ
```python
# YOLO ëª¨ë¸ë“¤ - ì§€ì—° ë¡œë”©ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ CUDA ì»¨í…ìŠ¤íŠ¸ ì¶©ëŒ ë°©ì§€
signal_model = None
yolo_models = None  
split_model = None

def get_signal_model():
    global signal_model
    if signal_model is None:
        cuda_context.push()
        try:
            signal_model = YOLO("model/signal.engine")
            print("âœ… Signal ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Signal ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            signal_model = None
        finally:
            cuda_context.pop()
    return signal_model

def get_yolo_models():
    global yolo_models
    if yolo_models is None:
        cuda_context.push()
        try:
            yolo_models = YOLO("model/1024x512.engine")
            print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            yolo_models = None
        finally:
            cuda_context.pop()
    return yolo_models

def get_split_model():
    global split_model
    if split_model is None:
        cuda_context.push()
        try:
            split_model = YOLO("model/sp.engine")
            print("âœ… Split ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Split ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            split_model = None
        finally:
            cuda_context.pop()
    return split_model
```

### 4. YOLO ëª¨ë¸ ì¶”ë¡  ì‹œ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

#### ê¸°ì¡´ ì½”ë“œ
```python
yolo_results = signal_model(frame)[0]
yolo_results2 = yolo_models(frame)[0]
yolo_result3 = split_model(frame)[0]
```

#### ìˆ˜ì •ëœ ì½”ë“œ
```python
# YOLO ëª¨ë¸ ì¶”ë¡  - CUDA ì»¨í…ìŠ¤íŠ¸ ëª…ì‹œì  ê´€ë¦¬
yolo_results = None
yolo_results2 = None
yolo_result3 = None

cuda_context.push()
try:
    signal_model_instance = get_signal_model()
    if signal_model_instance is not None:
        yolo_results = signal_model_instance(frame)[0]
    
    yolo_model_instance = get_yolo_models()
    if yolo_model_instance is not None:
        yolo_results2 = yolo_model_instance(frame)[0]
    
    split_model_instance = get_split_model()
    if split_model_instance is not None:
        yolo_result3 = split_model_instance(frame)[0]
        
except Exception as e:
    print(f"âš ï¸ YOLO ì¶”ë¡  ì—ëŸ¬: {e}")
    yolo_results = yolo_results2 = yolo_result3 = None
finally:
    cuda_context.pop()
```

### 5. ì•ˆì „í•œ ê²°ê³¼ ì²˜ë¦¬

#### ê¸°ì¡´ ì½”ë“œ
```python
for box in yolo_result3.boxes:
    # ë°”ë¡œ ì²˜ë¦¬
```

#### ìˆ˜ì •ëœ ì½”ë“œ
```python
if yolo_result3 is not None and hasattr(yolo_result3, 'boxes') and yolo_result3.boxes is not None:
    try:
        for box in yolo_result3.boxes:
            # ì•ˆì „í•œ ì²˜ë¦¬
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ê²°ê³¼ ì²˜ë¦¬ ì—ëŸ¬: {e}")
```

### 6. í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ CUDA ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬

```python
def main():
    # ... ë©”ì¸ ë¡œì§ ...
    
    cap.release()
    cv2.destroyAllWindows()
    
    # CUDA ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
    try:
        cuda_context.pop()
        cuda_context.detach()
        print("ğŸ§¹ CUDA ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ")
    except:
        pass
```

## í•µì‹¬ ì›ë¦¬

### 1. ë‹¨ì¼ CUDA ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
- ëª¨ë“  TensorRT ì—”ì§„ì´ ë™ì¼í•œ CUDA ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³µìœ 
- `cuda_context.push()`ì™€ `cuda_context.pop()`ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìŠ¤íƒ ê´€ë¦¬

### 2. ìˆœì°¨ì  ì‹¤í–‰ ë³´ì¥
- ì—¬ëŸ¬ ëª¨ë¸ì´ ë™ì‹œì— CUDA ë¦¬ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ì§€ ì•Šë„ë¡ ìˆœì°¨ ì‹¤í–‰
- ê° ì¶”ë¡  ì‘ì—…ì„ `try-finally` ë¸”ë¡ìœ¼ë¡œ ë³´í˜¸

### 3. ì§€ì—° ë¡œë”© íŒ¨í„´
- ëª¨ë¸ì„ í•„ìš”í•  ë•Œë§Œ ë¡œë“œí•˜ì—¬ ì´ˆê¸°í™” ì‹œì  ë¶„ì‚°
- ê° ëª¨ë¸ ë¡œë”© ì‹œì—ë„ CUDA ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì ìš©

### 4. ê°•ê±´í•œ ì˜ˆì™¸ ì²˜ë¦¬
- ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œì—ë„ í”„ë¡œê·¸ë¨ì´ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ ì²˜ë¦¬
- ì¶”ë¡  ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ `None` ë°˜í™˜

## ì ìš© ëŒ€ìƒ íŒŒì¼ë“¤

1. **main_tensor_sh.py** âœ… ì™„ë£Œ
2. **main_tensor.py** âœ… ì™„ë£Œ  
3. **main_tensor_split_ob.py** âœ… ì™„ë£Œ
4. **main_tensor_split_signal.py** âœ… ì™„ë£Œ

## ê²°ê³¼

### Before (ì˜¤ë¥˜ ë°œìƒ)
```bash
[TRT] [E] IExecutionContext::executeV2: Error Code 1: Cask (Cask convolution execution)
[TRT] [E] IExecutionContext::executeV2: Error Code 1: Cask (invalid resource handle)
```

### After (ì•ˆì •ì  ì‹¤í–‰)
```bash
âœ… Signal ëª¨ë¸ ë¡œë“œ ì™„ë£Œ
âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ  
âœ… Split ëª¨ë¸ ë¡œë“œ ì™„ë£Œ
[Frame 30] FPS: 12.34
[Frame 60] FPS: 13.21
ğŸ§¹ CUDA ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ
```

## ì£¼ì˜ì‚¬í•­

1. **ì»¨í…ìŠ¤íŠ¸ ìŠ¤íƒ ê· í˜•**: `push()`ì™€ `pop()` í˜¸ì¶œì´ ë°˜ë“œì‹œ ê· í˜•ì„ ì´ë¤„ì•¼ í•¨
2. **ì˜ˆì™¸ ì•ˆì „ì„±**: `finally` ë¸”ë¡ì—ì„œ ë°˜ë“œì‹œ `pop()` í˜¸ì¶œ
3. **ëª¨ë¸ ë¡œë”© ìˆœì„œ**: ì§€ì—° ë¡œë”©ìœ¼ë¡œ ëª¨ë¸ ê°„ ì˜ì¡´ì„± ì œê±°
4. **ë¦¬ì†ŒìŠ¤ ì •ë¦¬**: í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ `detach()` í˜¸ì¶œë¡œ ì™„ì „í•œ ì •ë¦¬

## ì„±ëŠ¥ ì˜í–¥

- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ì•½ê°„ ì¦ê°€ (ì»¨í…ìŠ¤íŠ¸ ìŠ¤íƒ ì˜¤ë²„í—¤ë“œ)
- **ì¶”ë¡  ì†ë„**: ê±°ì˜ ë™ì¼ (ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì˜¤ë²„í—¤ë“œ ë¯¸ë¯¸)
- **ì•ˆì •ì„±**: í¬ê²Œ í–¥ìƒ (ë¦¬ì†ŒìŠ¤ ì¶©ëŒ ì™„ì „ í•´ê²°)

ì´ ë°©ë²•ì„ í†µí•´ Jetson AGX Orinì—ì„œ TRTSegmenterì™€ ë‹¤ì¤‘ YOLO ëª¨ë¸ì„ ì•ˆì •ì ìœ¼ë¡œ ë™ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.